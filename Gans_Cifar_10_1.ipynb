{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense,LeakyReLU,Reshape,Conv2D,Conv2DTranspose,Dense,Flatten,Dropout\n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DC Gan on the cifar 10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"hyper parameters\"\"\"\n",
    "latent_dim = 32\n",
    "height = 32\n",
    "width = 32\n",
    "channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 32)]              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32768)             1081344   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 256)       819456    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 32, 32, 256)       1048832   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 32, 32, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 32, 32, 3)         37635     \n",
      "=================================================================\n",
      "Total params: 6,264,579\n",
      "Trainable params: 6,264,579\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"G_Net -> the generator network -> a conv net\"\"\"\n",
    "generator_input = keras.Input(shape=(latent_dim,))\n",
    "\n",
    "\n",
    "S = Dense(128 * 16 * 16)(generator_input)\n",
    "S = LeakyReLU()(S)\n",
    "S = Reshape((16, 16, 128))(S)\n",
    "\n",
    "\n",
    "S = Conv2D(256, 5, padding='same')(S)\n",
    "S = LeakyReLU()(S)\n",
    "\n",
    "\n",
    "S = Conv2DTranspose(256, 4, strides=2, padding='same')(S)\n",
    "S = LeakyReLU()(S)\n",
    "\n",
    "\n",
    "S = Conv2D(256, 5, padding='same')(S)\n",
    "S = LeakyReLU()(S)\n",
    "S = Conv2D(256, 5, padding='same')(S)\n",
    "S = LeakyReLU()(S)\n",
    "\n",
    "\n",
    "S = Conv2D(channels, 7, activation='tanh', padding='same')(S)\n",
    "G_Net = keras.models.Model(generator_input, S)\n",
    "G_Net.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 30, 30, 128)       3584      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 14, 14, 128)       262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 6, 6, 128)         262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 2, 2, 128)         262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 790,913\n",
      "Trainable params: 790,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"D_Net the discriminator for the gans\"\"\"\n",
    "discriminator_input = layers.Input(shape=(height, width, channels))\n",
    "S = Conv2D(128, 3)(discriminator_input)\n",
    "S = LeakyReLU()(S)\n",
    "S = Conv2D(128, 4, strides=2)(S)\n",
    "S = LeakyReLU()(S)\n",
    "S = Conv2D(128, 4, strides=2)(S)\n",
    "S = LeakyReLU()(S)\n",
    "S = Conv2D(128, 4, strides=2)(S)\n",
    "S = LeakyReLU()(S)\n",
    "S = Flatten()(S)\n",
    "\n",
    "\n",
    "S = Dropout(0.4)(S)\n",
    "\n",
    "\n",
    "S = Dense(1, activation='sigmoid')(S)  \n",
    "\n",
    "D_Net = keras.models.Model(discriminator_input, S)\n",
    "D_Net.summary()\n",
    "\n",
    "discriminator_optimizer = keras.optimizers.RMSprop(lr=0.0008, clipvalue=1.0, decay=1e-8)\n",
    "D_Net.compile(optimizer=discriminator_optimizer, loss='binary_crossentropy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_Net.trainable = False\n",
    "\n",
    "gan_input = keras.Input(shape=(latent_dim,))\n",
    "gan_output = D_Net(G_Net(gan_input))\n",
    "gans = keras.models.Model(gan_input, gan_output)\n",
    "\n",
    "gan_optimizer = keras.optimizers.RMSprop(lr=0.0004, clipvalue=1.0, decay=1e-8)\n",
    "gans.compile(optimizer=gan_optimizer, loss='binary_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Loading the cifar 10 datasaet\"\"\"\n",
    "(S_train, y_train), (_, _) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "\n",
    "S_train = S_train[y_train.flatten() == 5]\n",
    "\n",
    "\n",
    "S_train = S_train.reshape(\n",
    "    (S_train.shape[0],) + (height, width, channels)).astype('float32') / 255.\n",
    "\n",
    "iterations = 10000\n",
    "batch_size = 20\n",
    "save_dir = '/home/user/GAN_DC_MNIST/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator loss at step 0: 0.6986822485923767\n",
      "adversarial loss at step 0: 0.6768385767936707\n",
      "discriminator loss at step 10: 0.7533338665962219\n",
      "adversarial loss at step 10: 0.7962182760238647\n",
      "discriminator loss at step 20: 0.4859583377838135\n",
      "adversarial loss at step 20: 1.9407641887664795\n",
      "discriminator loss at step 30: 0.660897970199585\n",
      "adversarial loss at step 30: 0.6762562990188599\n",
      "discriminator loss at step 40: 0.7013099789619446\n",
      "adversarial loss at step 40: 0.6663370728492737\n",
      "discriminator loss at step 50: 0.6812707781791687\n",
      "adversarial loss at step 50: 0.6950147151947021\n",
      "discriminator loss at step 60: 0.6804402470588684\n",
      "adversarial loss at step 60: 0.7891403436660767\n",
      "discriminator loss at step 70: 0.7082245945930481\n",
      "adversarial loss at step 70: 1.6608175039291382\n",
      "discriminator loss at step 80: 0.7125769853591919\n",
      "adversarial loss at step 80: 0.9832416772842407\n",
      "discriminator loss at step 90: 0.6721616983413696\n",
      "adversarial loss at step 90: 0.8168312907218933\n",
      "discriminator loss at step 100: 0.6304052472114563\n",
      "adversarial loss at step 100: 1.1087814569473267\n",
      "discriminator loss at step 110: 0.6302816271781921\n",
      "adversarial loss at step 110: 1.1316401958465576\n",
      "discriminator loss at step 120: 0.5767135620117188\n",
      "adversarial loss at step 120: 2.0887417793273926\n",
      "discriminator loss at step 130: 0.690427839756012\n",
      "adversarial loss at step 130: 0.6702138185501099\n",
      "discriminator loss at step 140: 0.6984425783157349\n",
      "adversarial loss at step 140: 0.8312492370605469\n",
      "discriminator loss at step 150: 0.7695587873458862\n",
      "adversarial loss at step 150: 0.6746488809585571\n",
      "discriminator loss at step 160: 0.7428841590881348\n",
      "adversarial loss at step 160: 0.7888776659965515\n",
      "discriminator loss at step 170: 0.7081989049911499\n",
      "adversarial loss at step 170: 0.8995783925056458\n",
      "discriminator loss at step 180: 0.7223169207572937\n",
      "adversarial loss at step 180: 1.1068156957626343\n",
      "discriminator loss at step 190: 0.6961928606033325\n",
      "adversarial loss at step 190: 0.7020443081855774\n",
      "discriminator loss at step 200: 0.6900474429130554\n",
      "adversarial loss at step 200: 0.7905725836753845\n",
      "discriminator loss at step 210: 0.6864588856697083\n",
      "adversarial loss at step 210: 0.7806552648544312\n",
      "discriminator loss at step 220: 0.6783040761947632\n",
      "adversarial loss at step 220: 0.7662653923034668\n",
      "discriminator loss at step 230: 0.6793225407600403\n",
      "adversarial loss at step 230: 1.122581124305725\n",
      "discriminator loss at step 240: 0.7104266881942749\n",
      "adversarial loss at step 240: 0.8188611268997192\n",
      "discriminator loss at step 250: 0.6392326354980469\n",
      "adversarial loss at step 250: 2.1098058223724365\n",
      "discriminator loss at step 260: 0.7089409828186035\n",
      "adversarial loss at step 260: 0.7695086002349854\n",
      "discriminator loss at step 270: 0.8419649004936218\n",
      "adversarial loss at step 270: 1.1289341449737549\n",
      "discriminator loss at step 280: 0.7108049392700195\n",
      "adversarial loss at step 280: 0.8217664957046509\n",
      "discriminator loss at step 290: 0.6766498684883118\n",
      "adversarial loss at step 290: 0.8308302760124207\n",
      "discriminator loss at step 300: 0.687738299369812\n",
      "adversarial loss at step 300: 0.75298672914505\n",
      "discriminator loss at step 310: 0.7015279531478882\n",
      "adversarial loss at step 310: 0.8039580583572388\n",
      "discriminator loss at step 320: 0.6834692358970642\n",
      "adversarial loss at step 320: 0.7629592418670654\n",
      "discriminator loss at step 330: 0.6932925581932068\n",
      "adversarial loss at step 330: 0.7393931150436401\n",
      "discriminator loss at step 340: 0.6709745526313782\n",
      "adversarial loss at step 340: 0.7418711185455322\n",
      "discriminator loss at step 350: 0.7068349719047546\n",
      "adversarial loss at step 350: 0.7174080610275269\n",
      "discriminator loss at step 360: 0.694505512714386\n",
      "adversarial loss at step 360: 0.7704139947891235\n",
      "discriminator loss at step 370: 0.69153892993927\n",
      "adversarial loss at step 370: 0.739007830619812\n",
      "discriminator loss at step 380: 0.6911380887031555\n",
      "adversarial loss at step 380: 0.7620178461074829\n",
      "discriminator loss at step 390: 0.6056301593780518\n",
      "adversarial loss at step 390: 3.2480170726776123\n",
      "discriminator loss at step 400: 0.6792686581611633\n",
      "adversarial loss at step 400: 0.7445394992828369\n",
      "discriminator loss at step 410: 0.722876250743866\n",
      "adversarial loss at step 410: 0.8990246057510376\n",
      "discriminator loss at step 420: 0.7203359603881836\n",
      "adversarial loss at step 420: 0.7203928828239441\n",
      "discriminator loss at step 430: 0.712321400642395\n",
      "adversarial loss at step 430: 0.772508978843689\n",
      "discriminator loss at step 440: 0.7005447149276733\n",
      "adversarial loss at step 440: 0.7475711107254028\n",
      "discriminator loss at step 450: 0.7421672940254211\n",
      "adversarial loss at step 450: 0.6800175309181213\n",
      "discriminator loss at step 460: 0.724785327911377\n",
      "adversarial loss at step 460: 0.7642276883125305\n",
      "discriminator loss at step 470: 0.6994467973709106\n",
      "adversarial loss at step 470: 0.7677972316741943\n",
      "discriminator loss at step 480: 0.6577631235122681\n",
      "adversarial loss at step 480: 1.7155402898788452\n",
      "discriminator loss at step 490: 0.6833481788635254\n",
      "adversarial loss at step 490: 0.705572247505188\n",
      "discriminator loss at step 500: 0.7165951728820801\n",
      "adversarial loss at step 500: 0.8095458745956421\n",
      "discriminator loss at step 510: 0.6962541341781616\n",
      "adversarial loss at step 510: 0.7495428323745728\n",
      "discriminator loss at step 520: 0.7179549932479858\n",
      "adversarial loss at step 520: 0.7160031199455261\n",
      "discriminator loss at step 530: 0.683955192565918\n",
      "adversarial loss at step 530: 0.7192423939704895\n",
      "discriminator loss at step 540: 0.6299620866775513\n",
      "adversarial loss at step 540: 5.226943492889404\n",
      "discriminator loss at step 550: 0.6744028329849243\n",
      "adversarial loss at step 550: 0.9682501554489136\n",
      "discriminator loss at step 560: 0.7024814486503601\n",
      "adversarial loss at step 560: 0.7493408918380737\n",
      "discriminator loss at step 570: 0.6824081540107727\n",
      "adversarial loss at step 570: 0.7800936698913574\n",
      "discriminator loss at step 580: 0.6938360929489136\n",
      "adversarial loss at step 580: 0.8115655779838562\n",
      "discriminator loss at step 590: 0.7289915680885315\n",
      "adversarial loss at step 590: 0.988103985786438\n",
      "discriminator loss at step 600: 0.7072463035583496\n",
      "adversarial loss at step 600: 0.7450693845748901\n",
      "discriminator loss at step 610: 0.6864970922470093\n",
      "adversarial loss at step 610: 0.7496851682662964\n",
      "discriminator loss at step 620: 0.6846293807029724\n",
      "adversarial loss at step 620: 0.7529908418655396\n",
      "discriminator loss at step 630: 0.6816661357879639\n",
      "adversarial loss at step 630: 0.7912352681159973\n",
      "discriminator loss at step 640: 0.7071776390075684\n",
      "adversarial loss at step 640: 1.2756006717681885\n",
      "discriminator loss at step 650: 0.6578856706619263\n",
      "adversarial loss at step 650: 0.7624672651290894\n",
      "discriminator loss at step 660: 0.7002881765365601\n",
      "adversarial loss at step 660: 0.7441818714141846\n",
      "discriminator loss at step 670: 0.6894422173500061\n",
      "adversarial loss at step 670: 0.7267245054244995\n",
      "discriminator loss at step 680: 0.7019811868667603\n",
      "adversarial loss at step 680: 0.7707057595252991\n",
      "discriminator loss at step 690: 0.713366687297821\n",
      "adversarial loss at step 690: 0.7455403804779053\n",
      "discriminator loss at step 700: 0.907545268535614\n",
      "adversarial loss at step 700: 0.7248956561088562\n",
      "discriminator loss at step 710: 0.6548210382461548\n",
      "adversarial loss at step 710: 0.9390286207199097\n",
      "discriminator loss at step 720: 0.6968125104904175\n",
      "adversarial loss at step 720: 0.7657901048660278\n",
      "discriminator loss at step 730: 0.7688436508178711\n",
      "adversarial loss at step 730: 0.7582827806472778\n",
      "discriminator loss at step 740: 0.690069317817688\n",
      "adversarial loss at step 740: 0.7473272085189819\n",
      "discriminator loss at step 750: 0.7488791942596436\n",
      "adversarial loss at step 750: 0.7772661447525024\n",
      "discriminator loss at step 760: 0.681923508644104\n",
      "adversarial loss at step 760: 0.7676728963851929\n",
      "discriminator loss at step 770: 0.6926799416542053\n",
      "adversarial loss at step 770: 0.727040708065033\n",
      "discriminator loss at step 780: 0.6991310715675354\n",
      "adversarial loss at step 780: 0.7587045431137085\n",
      "discriminator loss at step 790: 0.871624767780304\n",
      "adversarial loss at step 790: 0.7882224321365356\n",
      "discriminator loss at step 800: 0.7249199151992798\n",
      "adversarial loss at step 800: 0.8514021635055542\n",
      "discriminator loss at step 810: 0.6888197064399719\n",
      "adversarial loss at step 810: 0.7609001398086548\n",
      "discriminator loss at step 820: 0.6952991485595703\n",
      "adversarial loss at step 820: 0.7447361350059509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator loss at step 830: 0.7380880117416382\n",
      "adversarial loss at step 830: 0.8248098492622375\n",
      "discriminator loss at step 840: 0.7220908999443054\n",
      "adversarial loss at step 840: 0.7173399925231934\n",
      "discriminator loss at step 850: 0.6801667213439941\n",
      "adversarial loss at step 850: 0.7956535220146179\n",
      "discriminator loss at step 860: 0.6848591566085815\n",
      "adversarial loss at step 860: 0.7576422691345215\n",
      "discriminator loss at step 870: 0.7138684988021851\n",
      "adversarial loss at step 870: 0.7190700769424438\n",
      "discriminator loss at step 880: 0.6859742403030396\n",
      "adversarial loss at step 880: 0.6889955997467041\n",
      "discriminator loss at step 890: 0.689436137676239\n",
      "adversarial loss at step 890: 0.7250558733940125\n",
      "discriminator loss at step 900: 0.6937959790229797\n",
      "adversarial loss at step 900: 0.7711201906204224\n",
      "discriminator loss at step 910: 0.6993324160575867\n",
      "adversarial loss at step 910: 0.7685433626174927\n",
      "discriminator loss at step 920: 0.6962539553642273\n",
      "adversarial loss at step 920: 0.7620679140090942\n",
      "discriminator loss at step 930: 0.6937050819396973\n",
      "adversarial loss at step 930: 0.7834113836288452\n",
      "discriminator loss at step 940: 0.7015627026557922\n",
      "adversarial loss at step 940: 0.7447596788406372\n",
      "discriminator loss at step 950: 0.6951051950454712\n",
      "adversarial loss at step 950: 0.7423025369644165\n",
      "discriminator loss at step 960: 0.6961588859558105\n",
      "adversarial loss at step 960: 0.7690054774284363\n",
      "discriminator loss at step 970: 0.6958113312721252\n",
      "adversarial loss at step 970: 0.7382197976112366\n",
      "discriminator loss at step 980: 0.6970611810684204\n",
      "adversarial loss at step 980: 0.7204244136810303\n",
      "discriminator loss at step 990: 0.8250250816345215\n",
      "adversarial loss at step 990: 0.7516047954559326\n",
      "discriminator loss at step 1000: 0.6841611266136169\n",
      "adversarial loss at step 1000: 0.699981689453125\n",
      "discriminator loss at step 1010: 0.7057136297225952\n",
      "adversarial loss at step 1010: 0.7603997588157654\n",
      "discriminator loss at step 1020: 0.6967542171478271\n",
      "adversarial loss at step 1020: 0.7872506976127625\n",
      "discriminator loss at step 1030: 1.032288908958435\n",
      "adversarial loss at step 1030: 0.9117488861083984\n",
      "discriminator loss at step 1040: 0.6998565793037415\n",
      "adversarial loss at step 1040: 0.7210186123847961\n",
      "discriminator loss at step 1050: 0.6986578106880188\n",
      "adversarial loss at step 1050: 0.7528067827224731\n",
      "discriminator loss at step 1060: 0.715050995349884\n",
      "adversarial loss at step 1060: 0.7363561391830444\n",
      "discriminator loss at step 1070: 0.6943994164466858\n",
      "adversarial loss at step 1070: 0.7541364431381226\n",
      "discriminator loss at step 1080: 0.6995280981063843\n",
      "adversarial loss at step 1080: 0.7396903038024902\n",
      "discriminator loss at step 1090: 0.686342179775238\n",
      "adversarial loss at step 1090: 0.7334197759628296\n",
      "discriminator loss at step 1100: 0.6871495842933655\n",
      "adversarial loss at step 1100: 0.8125079870223999\n",
      "discriminator loss at step 1110: 0.6928427815437317\n",
      "adversarial loss at step 1110: 0.7367957830429077\n",
      "discriminator loss at step 1120: 0.7240853309631348\n",
      "adversarial loss at step 1120: 0.8392419815063477\n",
      "discriminator loss at step 1130: 0.7056418657302856\n",
      "adversarial loss at step 1130: 0.817584216594696\n",
      "discriminator loss at step 1140: 0.67620849609375\n",
      "adversarial loss at step 1140: 0.9169170260429382\n",
      "discriminator loss at step 1150: 0.7022181749343872\n",
      "adversarial loss at step 1150: 0.735906183719635\n",
      "discriminator loss at step 1160: 0.6873392462730408\n",
      "adversarial loss at step 1160: 0.7459573149681091\n",
      "discriminator loss at step 1170: 0.668420135974884\n",
      "adversarial loss at step 1170: 0.7661429643630981\n",
      "discriminator loss at step 1180: 0.8382006883621216\n",
      "adversarial loss at step 1180: 0.735095202922821\n",
      "discriminator loss at step 1190: 0.7097649574279785\n",
      "adversarial loss at step 1190: 0.7592096328735352\n",
      "discriminator loss at step 1200: 0.6883025169372559\n",
      "adversarial loss at step 1200: 0.7592146992683411\n",
      "discriminator loss at step 1210: 0.7194787263870239\n",
      "adversarial loss at step 1210: 0.8067735433578491\n",
      "discriminator loss at step 1220: 0.6960148811340332\n",
      "adversarial loss at step 1220: 0.7418187856674194\n",
      "discriminator loss at step 1230: 0.7064532041549683\n",
      "adversarial loss at step 1230: 0.7596514821052551\n",
      "discriminator loss at step 1240: 0.7025629281997681\n",
      "adversarial loss at step 1240: 0.7601224184036255\n",
      "discriminator loss at step 1250: 0.6891660094261169\n",
      "adversarial loss at step 1250: 0.867491602897644\n",
      "discriminator loss at step 1260: 0.6950658559799194\n",
      "adversarial loss at step 1260: 0.8091036677360535\n",
      "discriminator loss at step 1270: 0.6970720291137695\n",
      "adversarial loss at step 1270: 0.7803745269775391\n",
      "discriminator loss at step 1280: 0.6864970922470093\n",
      "adversarial loss at step 1280: 0.7560045719146729\n",
      "discriminator loss at step 1290: 0.7252527475357056\n",
      "adversarial loss at step 1290: 1.1920949220657349\n",
      "discriminator loss at step 1300: 0.6858944296836853\n",
      "adversarial loss at step 1300: 0.7532451748847961\n",
      "discriminator loss at step 1310: 0.7081001996994019\n",
      "adversarial loss at step 1310: 0.6832315325737\n",
      "discriminator loss at step 1320: 0.6967800855636597\n",
      "adversarial loss at step 1320: 0.768614649772644\n",
      "discriminator loss at step 1330: 0.6828089952468872\n",
      "adversarial loss at step 1330: 0.7677614688873291\n",
      "discriminator loss at step 1340: 0.6833748817443848\n",
      "adversarial loss at step 1340: 0.6671255230903625\n",
      "discriminator loss at step 1350: 0.694197952747345\n",
      "adversarial loss at step 1350: 0.7765993475914001\n",
      "discriminator loss at step 1360: 0.7019899487495422\n",
      "adversarial loss at step 1360: 0.7875548601150513\n",
      "discriminator loss at step 1370: 0.7044154405593872\n",
      "adversarial loss at step 1370: 0.8202055096626282\n",
      "discriminator loss at step 1380: 0.6964077949523926\n",
      "adversarial loss at step 1380: 0.7758651971817017\n",
      "discriminator loss at step 1390: 0.6867117881774902\n",
      "adversarial loss at step 1390: 0.7629529237747192\n",
      "discriminator loss at step 1400: 0.7270519733428955\n",
      "adversarial loss at step 1400: 0.7738001942634583\n",
      "discriminator loss at step 1410: 0.700247585773468\n",
      "adversarial loss at step 1410: 0.9781848192214966\n",
      "discriminator loss at step 1420: 0.6938322186470032\n",
      "adversarial loss at step 1420: 0.758041501045227\n",
      "discriminator loss at step 1430: 0.6910318732261658\n",
      "adversarial loss at step 1430: 0.7640802264213562\n",
      "discriminator loss at step 1440: 0.6867843270301819\n",
      "adversarial loss at step 1440: 0.7468417882919312\n",
      "discriminator loss at step 1450: 0.6831711530685425\n",
      "adversarial loss at step 1450: 1.7851998805999756\n",
      "discriminator loss at step 1460: 0.6859970092773438\n",
      "adversarial loss at step 1460: 0.7634831666946411\n",
      "discriminator loss at step 1470: 0.7020373344421387\n",
      "adversarial loss at step 1470: 0.7652097344398499\n",
      "discriminator loss at step 1480: 0.6945476531982422\n",
      "adversarial loss at step 1480: 0.7506471872329712\n",
      "discriminator loss at step 1490: 0.6885994672775269\n",
      "adversarial loss at step 1490: 0.7350602746009827\n",
      "discriminator loss at step 1500: 0.705876350402832\n",
      "adversarial loss at step 1500: 0.7903090119361877\n",
      "discriminator loss at step 1510: 0.6996164321899414\n",
      "adversarial loss at step 1510: 0.746393084526062\n",
      "discriminator loss at step 1520: 0.7694281339645386\n",
      "adversarial loss at step 1520: 0.7448119521141052\n",
      "discriminator loss at step 1530: 0.6923390626907349\n",
      "adversarial loss at step 1530: 0.7565179467201233\n",
      "discriminator loss at step 1540: 0.6907516717910767\n",
      "adversarial loss at step 1540: 0.7634466290473938\n",
      "discriminator loss at step 1550: 0.6940215229988098\n",
      "adversarial loss at step 1550: 0.7485829591751099\n",
      "discriminator loss at step 1560: 0.7002303004264832\n",
      "adversarial loss at step 1560: 0.7454324960708618\n",
      "discriminator loss at step 1570: 0.6910479664802551\n",
      "adversarial loss at step 1570: 0.7329326868057251\n",
      "discriminator loss at step 1580: 0.7024477124214172\n",
      "adversarial loss at step 1580: 0.7660635709762573\n",
      "discriminator loss at step 1590: 0.6909464597702026\n",
      "adversarial loss at step 1590: 0.8256199955940247\n",
      "discriminator loss at step 1600: 0.685068666934967\n",
      "adversarial loss at step 1600: 0.8674038052558899\n",
      "discriminator loss at step 1610: 0.6837695240974426\n",
      "adversarial loss at step 1610: 0.7906705141067505\n",
      "discriminator loss at step 1620: 0.6989049911499023\n",
      "adversarial loss at step 1620: 0.7459207773208618\n",
      "discriminator loss at step 1630: 0.662885844707489\n",
      "adversarial loss at step 1630: 0.7151544690132141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator loss at step 1640: 0.6956079602241516\n",
      "adversarial loss at step 1640: 0.7413477897644043\n",
      "discriminator loss at step 1650: 0.6911591291427612\n",
      "adversarial loss at step 1650: 0.7664481997489929\n",
      "discriminator loss at step 1660: 0.6949762105941772\n",
      "adversarial loss at step 1660: 0.7447986006736755\n",
      "discriminator loss at step 1670: 0.7027126550674438\n",
      "adversarial loss at step 1670: 0.7398961782455444\n",
      "discriminator loss at step 1680: 0.6882286071777344\n",
      "adversarial loss at step 1680: 0.7280006408691406\n",
      "discriminator loss at step 1690: 0.6955105066299438\n",
      "adversarial loss at step 1690: 0.7617189288139343\n",
      "discriminator loss at step 1700: 0.6966027021408081\n",
      "adversarial loss at step 1700: 0.8054065704345703\n",
      "discriminator loss at step 1710: 0.6768878698348999\n",
      "adversarial loss at step 1710: 0.8281599879264832\n",
      "discriminator loss at step 1720: 0.7005088925361633\n",
      "adversarial loss at step 1720: 0.7682393789291382\n",
      "discriminator loss at step 1730: 0.7019973397254944\n",
      "adversarial loss at step 1730: 0.7702133059501648\n",
      "discriminator loss at step 1740: 0.6858113408088684\n",
      "adversarial loss at step 1740: 0.7390941977500916\n",
      "discriminator loss at step 1750: 0.695041298866272\n",
      "adversarial loss at step 1750: 0.7628575563430786\n",
      "discriminator loss at step 1760: 0.6995990872383118\n",
      "adversarial loss at step 1760: 0.7800292372703552\n",
      "discriminator loss at step 1770: 0.6895385980606079\n",
      "adversarial loss at step 1770: 0.759414792060852\n",
      "discriminator loss at step 1780: 0.6797856688499451\n",
      "adversarial loss at step 1780: 0.7361353039741516\n",
      "discriminator loss at step 1790: 0.6885290145874023\n",
      "adversarial loss at step 1790: 0.7537100911140442\n",
      "discriminator loss at step 1800: 0.7069954872131348\n",
      "adversarial loss at step 1800: 0.8067550659179688\n",
      "discriminator loss at step 1810: 0.669003963470459\n",
      "adversarial loss at step 1810: 0.7021138072013855\n",
      "discriminator loss at step 1820: 0.6900886297225952\n",
      "adversarial loss at step 1820: 0.7362614870071411\n",
      "discriminator loss at step 1830: 0.69899582862854\n",
      "adversarial loss at step 1830: 0.7454982995986938\n",
      "discriminator loss at step 1840: 0.699738621711731\n",
      "adversarial loss at step 1840: 0.9609413146972656\n",
      "discriminator loss at step 1850: 0.6866775155067444\n",
      "adversarial loss at step 1850: 0.7386182546615601\n",
      "discriminator loss at step 1860: 0.6908925175666809\n",
      "adversarial loss at step 1860: 0.8017622828483582\n",
      "discriminator loss at step 1870: 0.7030603289604187\n",
      "adversarial loss at step 1870: 0.7790877223014832\n",
      "discriminator loss at step 1880: 0.7516248226165771\n",
      "adversarial loss at step 1880: 0.9023250341415405\n",
      "discriminator loss at step 1890: 0.6868473887443542\n",
      "adversarial loss at step 1890: 0.7626577019691467\n",
      "discriminator loss at step 1900: 0.6785335540771484\n",
      "adversarial loss at step 1900: 0.7448379397392273\n",
      "discriminator loss at step 1910: 0.7194637060165405\n",
      "adversarial loss at step 1910: 0.7847193479537964\n",
      "discriminator loss at step 1920: 0.713667094707489\n",
      "adversarial loss at step 1920: 0.761158287525177\n",
      "discriminator loss at step 1930: 0.6893450021743774\n",
      "adversarial loss at step 1930: 0.7726730108261108\n",
      "discriminator loss at step 1940: 0.6925972104072571\n",
      "adversarial loss at step 1940: 0.9074493646621704\n",
      "discriminator loss at step 1950: 0.6707122921943665\n",
      "adversarial loss at step 1950: 0.7017024755477905\n",
      "discriminator loss at step 1960: 0.6757410764694214\n",
      "adversarial loss at step 1960: 0.750190258026123\n",
      "discriminator loss at step 1970: 0.6651231050491333\n",
      "adversarial loss at step 1970: 1.0054237842559814\n",
      "discriminator loss at step 1980: 0.7278890013694763\n",
      "adversarial loss at step 1980: 0.7904268503189087\n",
      "discriminator loss at step 1990: 0.7082672119140625\n",
      "adversarial loss at step 1990: 0.760333240032196\n",
      "discriminator loss at step 2000: 0.6809878349304199\n",
      "adversarial loss at step 2000: 0.7975925207138062\n",
      "discriminator loss at step 2010: 0.6922786831855774\n",
      "adversarial loss at step 2010: 0.8271109461784363\n",
      "discriminator loss at step 2020: 0.6924594640731812\n",
      "adversarial loss at step 2020: 0.8688543438911438\n",
      "discriminator loss at step 2030: 0.6860982775688171\n",
      "adversarial loss at step 2030: 0.9837805032730103\n",
      "discriminator loss at step 2040: 0.6972612142562866\n",
      "adversarial loss at step 2040: 0.7579063177108765\n",
      "discriminator loss at step 2050: 0.7070727348327637\n",
      "adversarial loss at step 2050: 0.8054308891296387\n",
      "discriminator loss at step 2060: 0.683391273021698\n",
      "adversarial loss at step 2060: 0.7568305134773254\n",
      "discriminator loss at step 2070: 0.6901724338531494\n",
      "adversarial loss at step 2070: 0.7786378860473633\n",
      "discriminator loss at step 2080: 0.7027022838592529\n",
      "adversarial loss at step 2080: 0.7428094148635864\n",
      "discriminator loss at step 2090: 0.6870989799499512\n",
      "adversarial loss at step 2090: 0.9049848318099976\n",
      "discriminator loss at step 2100: 0.657052218914032\n",
      "adversarial loss at step 2100: 0.6932103037834167\n",
      "discriminator loss at step 2110: 0.6844931840896606\n",
      "adversarial loss at step 2110: 0.759092390537262\n",
      "discriminator loss at step 2120: 0.6884216666221619\n",
      "adversarial loss at step 2120: 0.7760505676269531\n",
      "discriminator loss at step 2130: 0.6852685809135437\n",
      "adversarial loss at step 2130: 0.7637807130813599\n",
      "discriminator loss at step 2140: 0.6748758554458618\n",
      "adversarial loss at step 2140: 0.8056812286376953\n",
      "discriminator loss at step 2150: 0.7203773260116577\n",
      "adversarial loss at step 2150: 0.7886767387390137\n",
      "discriminator loss at step 2160: 0.702543318271637\n",
      "adversarial loss at step 2160: 0.9782681465148926\n",
      "discriminator loss at step 2170: 0.6964386701583862\n",
      "adversarial loss at step 2170: 0.7986591458320618\n",
      "discriminator loss at step 2180: 0.7394335269927979\n",
      "adversarial loss at step 2180: 0.7745348811149597\n",
      "discriminator loss at step 2190: 0.7098729610443115\n",
      "adversarial loss at step 2190: 0.7555144429206848\n",
      "discriminator loss at step 2200: 0.655173122882843\n",
      "adversarial loss at step 2200: 0.7940281629562378\n",
      "discriminator loss at step 2210: 0.7040073871612549\n",
      "adversarial loss at step 2210: 0.701454758644104\n",
      "discriminator loss at step 2220: 0.6832646727561951\n",
      "adversarial loss at step 2220: 0.7366063594818115\n",
      "discriminator loss at step 2230: 0.6904128789901733\n",
      "adversarial loss at step 2230: 0.7907310724258423\n",
      "discriminator loss at step 2240: 0.7029081583023071\n",
      "adversarial loss at step 2240: 0.7604726552963257\n",
      "discriminator loss at step 2250: 0.7681446075439453\n",
      "adversarial loss at step 2250: 0.7160588502883911\n",
      "discriminator loss at step 2260: 0.7047321200370789\n",
      "adversarial loss at step 2260: 0.6981903910636902\n",
      "discriminator loss at step 2270: 0.6989210247993469\n",
      "adversarial loss at step 2270: 0.7349539995193481\n",
      "discriminator loss at step 2280: 0.6897190809249878\n",
      "adversarial loss at step 2280: 0.822506308555603\n",
      "discriminator loss at step 2290: 0.6960961818695068\n",
      "adversarial loss at step 2290: 0.7343816757202148\n",
      "discriminator loss at step 2300: 0.6796833872795105\n",
      "adversarial loss at step 2300: 0.7751563191413879\n",
      "discriminator loss at step 2310: 0.6811944246292114\n",
      "adversarial loss at step 2310: 0.8414322137832642\n",
      "discriminator loss at step 2320: 0.7060095071792603\n",
      "adversarial loss at step 2320: 0.764477550983429\n",
      "discriminator loss at step 2330: 0.6844782829284668\n",
      "adversarial loss at step 2330: 0.7174963355064392\n",
      "discriminator loss at step 2340: 0.690215528011322\n",
      "adversarial loss at step 2340: 0.7545996904373169\n",
      "discriminator loss at step 2350: 0.6890208125114441\n",
      "adversarial loss at step 2350: 0.7711217999458313\n",
      "discriminator loss at step 2360: 0.7081178426742554\n",
      "adversarial loss at step 2360: 0.6775259971618652\n",
      "discriminator loss at step 2370: 0.7099028825759888\n",
      "adversarial loss at step 2370: 0.7161062955856323\n",
      "discriminator loss at step 2380: 0.701183557510376\n",
      "adversarial loss at step 2380: 0.7917319536209106\n",
      "discriminator loss at step 2390: 0.6871606111526489\n",
      "adversarial loss at step 2390: 0.7584096789360046\n",
      "discriminator loss at step 2400: 0.6791502237319946\n",
      "adversarial loss at step 2400: 0.7775598168373108\n",
      "discriminator loss at step 2410: 0.694973349571228\n",
      "adversarial loss at step 2410: 0.7652676701545715\n",
      "discriminator loss at step 2420: 0.6820255517959595\n",
      "adversarial loss at step 2420: 0.7676081657409668\n",
      "discriminator loss at step 2430: 0.6879288554191589\n",
      "adversarial loss at step 2430: 0.7747721672058105\n",
      "discriminator loss at step 2440: 0.7048624753952026\n",
      "adversarial loss at step 2440: 0.7516148686408997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator loss at step 2450: 0.6920853853225708\n",
      "adversarial loss at step 2450: 0.6830207705497742\n",
      "discriminator loss at step 2460: 0.6935537457466125\n",
      "adversarial loss at step 2460: 0.7172161340713501\n",
      "discriminator loss at step 2470: 0.6835787892341614\n",
      "adversarial loss at step 2470: 0.7800552248954773\n",
      "discriminator loss at step 2480: 0.6997838616371155\n",
      "adversarial loss at step 2480: 0.9042618870735168\n",
      "discriminator loss at step 2490: 0.6845744848251343\n",
      "adversarial loss at step 2490: 0.7355608344078064\n",
      "discriminator loss at step 2500: 0.6823652982711792\n",
      "adversarial loss at step 2500: 0.7830003499984741\n",
      "discriminator loss at step 2510: 0.6712144017219543\n",
      "adversarial loss at step 2510: 0.7139980792999268\n",
      "discriminator loss at step 2520: 0.6969900131225586\n",
      "adversarial loss at step 2520: 0.8317155838012695\n",
      "discriminator loss at step 2530: 0.7083925604820251\n",
      "adversarial loss at step 2530: 0.8681570887565613\n",
      "discriminator loss at step 2540: 0.6789073944091797\n",
      "adversarial loss at step 2540: 0.7564944624900818\n",
      "discriminator loss at step 2550: 0.6550560593605042\n",
      "adversarial loss at step 2550: 1.079392910003662\n",
      "discriminator loss at step 2560: 0.6797093152999878\n",
      "adversarial loss at step 2560: 0.8505657911300659\n",
      "discriminator loss at step 2570: 0.7112977504730225\n",
      "adversarial loss at step 2570: 0.7171936631202698\n",
      "discriminator loss at step 2580: 0.7357841730117798\n",
      "adversarial loss at step 2580: 0.7402609586715698\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Training the network\"\"\"\n",
    "start = 0\n",
    "\n",
    "for step in range(iterations):\n",
    "    random_latent_vectors = np.random.normal(size = (batch_size,latent_dim))\n",
    "    generated_images = G_Net.predict(random_latent_vectors)\n",
    "    stop = start + batch_size\n",
    "    real_images = S_train[start:stop]\n",
    "    combined_images = np.concatenate([generated_images,real_images])\n",
    "    \n",
    "    labels = np.concatenate([np.ones((batch_size, 1)),\n",
    "                             np.zeros((batch_size, 1))])\n",
    "    \n",
    "    labels += 0.05 * np.random.random(labels.shape)\n",
    "\n",
    "                            \n",
    "    d_loss = D_Net.train_on_batch(combined_images,labels)\n",
    "    random_latent_vectors = np.random.normal(size = (batch_size,latent_dim))\n",
    "    misleading_targets = np.zeros((batch_size,1))\n",
    "    \n",
    "    a_loss = gans.train_on_batch(random_latent_vectors, misleading_targets)\n",
    "    \n",
    "    start += batch_size\n",
    "    if start > len(S_train) - batch_size:\n",
    "       start = 0\n",
    "\n",
    "    \n",
    "    if step % 10 == 0:\n",
    "        \n",
    "        gans.save_weights('gan.h5')\n",
    "\n",
    "        \n",
    "        print('discriminator loss at step %s: %s' % (step, d_loss))\n",
    "        print('adversarial loss at step %s: %s' % (step, a_loss))\n",
    "\n",
    "        \n",
    "        img = image.array_to_img(generated_images[0] * 255., scale=False)\n",
    "        img.save(os.path.join(save_dir, 'generated_Dog' + str(step) + '.png'))\n",
    "\n",
    "        \n",
    "        img = image.array_to_img(real_images[0] * 255., scale=False)\n",
    "        img.save(os.path.join(save_dir, 'real_Dog' + str(step) + '.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
